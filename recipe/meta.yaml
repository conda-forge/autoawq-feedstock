{% set version = "0.2.6" %}

package:
  name: autoawq
  version: {{ version }}

source:
  url: https://github.com/casper-hansen/autoawq/archive/refs/tags/v{{ version }}.tar.gz
  sha256: e6a3451d1d4cf69cd81cbb816593d6c4144d323c221354b56d1496afd46ec129

build:
  rpaths:
    - lib/
  script_env:
    - DISABLE_QIGEN=1 # coming soon
    - TORCH_CUDA_ARCH_LIST=3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6;8.9+PTX  # [cuda_compiler_version == "11.8"]
    - TORCH_CUDA_ARCH_LIST=5.0;6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0+PTX  # [(cuda_compiler_version or "").startswith("12")]
    - CPATH=${BUILD_PREFIX}/include
  script: |
    cat setup.py | sed 's/os.environ\["CC"\] = "g++"//' | sed 's/os.environ\["CXX"\] = "g++"//' > tmpsetup.py
    mv tmpsetup.py setup.py
    {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0
  skip: true  # [cuda_compiler_version == "None"]
  skip: true  # [osx or win]
  skip: true  # [py == 38]
  missing_dso_whitelist:
    - '*/libtorch_python.so'

requirements:
  build:
    - cmake
    - make
    - {{ compiler('c') }}
    - {{ stdlib("c") }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}

  host:
    - python
    - packaging
    - setuptools >=49.4.0
    - pytorch >=2.1.0
    - wheel
    - pip
    - requests
    - libxcrypt
  run:
    - python
    - pytorch
    - torchvision
    - transformers >=4.35.0
    - tokenizers >=0.12.1
    - accelerate
    - sentencepiece
    - lm_eval
    - texttable
    - toml
    - attributedict
    - protobuf
    - torchvision
    - tabulate
    - libtorch

test:
  imports:
    - awq
  # commands: # pending https://github.com/conda-forge/tcolorpy-feedstock/issues/12
  #   - pip check
  requires:
    - pip

about:
  home: https://github.com/casper-hansen/AutoAWQ
  summary: AutoAWQ is an easy-to-use package for 4-bit quantized models.
  license: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - mediocretech
    - h-vetinari
